---
title: "Power and sample size calculations"
author: "Dave Harrington"
date: "May 14 - 18, 2018"
output: 
  beamer_presentation:
     includes:
       in_header: ../survival_header.tex
     fig_width: 3.25
     fig_height: 3.0
     fig_caption: true
     toc: true
     keep_tex: true
slide_level: 3
urlcolor: darkblue 
linkcolor: darkblue
citecolor: darkblue

--- 


# Background

### An example

![](../figures/sprint.pdf){width=70%}

See publication by [\textcolor{darkblue}{SPRINT writing committee}](../../clinical_papers/SPRINT_nejm.pdf).

### Design of SPRINT

From the methods section of the paper:

\vspace{2em}

\begin{quote}
We planned a 2-year recruitment period, with a maximum follow-up of 6 years, and anticipated a loss to follow-up of 2\% per year. With an enrollment target of 9250 participants, we estimated  that the trial would have 88.7\% power to detect  a 20\% effect with respect to the primary outcome, assuming an event rate of 2.2\% in the standard-treatment group.
\end{quote}

### Type I error

Type I error (alpha error)

- Probability that trial will report a false positive, i.e., claim a significant result when there is no treatment effect

- Typically set no larger than 5%

- Depends on method of analysis, does not depend on sample size

### Power 

- Probability that the trial will report a true positive, i.e., claim a significant result when there is a treatment effect

- Should be 80% or greater

- Depends on sample size, method of analysis, and size of treatment effect.

- Power calculations relevant when study is designed

- Power calculations have little value after a study is complete.

    -  Precision measured through confidence intervals

### Overview of sample size for censored data


This unit focuses on the power of tests based on the exponential distribution and the log-rank test.

As in standard designs, the power depends on 

- Type I error (significance level $\alpha$) 

- Difference of interest, $\Delta$, under an alternative hypothesis $H_A$.

A notable difference from the usual scenario is that power depends on the **number of failures** that will be observed, not the total sample size. 

### Overview \ldots

In practice, designing a survival study involves deciding how many patients or individuals to enter, as well as how long they  should be followed.

Designs are usually either   

- *fixed sample size*, with the sample size determined in advance, or 

- *sequential*, which incorporate the possibility of stopping early for efficacy or futility

Collett, Chapter 12 covers sample size calculations.




# Power calculations for normally distributed observations 

### Testing for differences between two means
 
Suppose data consist of:

- Group 1: $(Y_{11}, \dots Y_{1n_1})$
- Group 0: $(Y_{01}, \dots Y_{0n_0})$

Assume
\[
Y_{1j} \sim N(\mu_1,\sigma^2),  ~ Y_{0j} \sim N(\mu_0,\sigma^2)
\]

The usual objective is to test:
\[ 
H_0:  \mu_1 = \mu_0 \Rightarrow  ~ H_0: \triangle = 0,~
\text{where } \triangle = \mu_1 - \mu_0
\]


### Power for a two sample normal 

The standard test is based on the $Z$ statistic:

\[   Z = \frac{\overline{Y}_1 - \overline{Y}_0}
       {\sqrt{s^2 (\frac{1}{n_1} +\frac{1}{n_0}})} \]
where $s^2$ is the pooled sample variance (assuming equal variances).  

This test statistic has a $N(0,1)$ distribution under $H_0$.
If the sample sizes are equal in the two groups, $n_0=n_1=n/2$, then:

\begin{align*}
Z &= \frac{\overline{Y}_1 - \overline{Y}_0}
{\sqrt{s^2 (\frac{1}{n/2} +\frac{1}{n/2}})} = 
\frac{\overline{Y}_1 - \overline{Y}_0}{2s/\sqrt{n}}
\end{align*}

### The steps for calculating sample size

1. Determine the critical value, $c$, for rejecting the null when it is true.

2. Calculate the probability of rejecting the null when the alternative is true, substituting $c$ from above.

3. Write the expression in terms of sample size for a given power.

### Step 1

Set the significance level, $\alpha$, the probability of rejecting the null hypothesis when it is true, and solve for $c$:
\begin{align*}
\alpha &=  P\left(|\overline{Y_1} - 
\overline{Y_0}| > c ~|~ H_0\right)\\[1ex]
&=  P\left(\frac{|\overline{Y_1} - \overline{Y_0}|}{2s/\sqrt{n}} > 
\frac{c}{2s/\sqrt{n}} ~|~ H_0 \right) \\[1ex]
&= P\left(|Z| > \frac{c}{2s/\sqrt{n}}\right) = 
2  \Phi\left(\frac{c}{2s/\sqrt{n}}\right) \\[1ex]
\text{so } z_{1-\alpha/2} &=  \frac{c}{2s/\sqrt{n}}\\[2ex]
\text{or  } c &= \frac{z_{1-\alpha/2} (2)(s)}{\sqrt{n}}
\end{align*}

Note that $z_{\gamma}$ is the value such that
$\Phi(z_{\gamma})=Pr(Z<z_{\gamma}) = \gamma$.

### Step 2: power as a function of sample size

Calculate the probability of rejecting the null when $H_A$ is true.

Begin by writing down the probability of a Type II error:
\begin{align*}
\beta &= P\left(\text{accept $H_0$} ~|~ H_A\right)\\
\text{so power } =  1-\beta &=   P\left(\text{reject $H_0$} ~|~ H_A\right)\\
&=P\left(|\overline{Y}_1 - \overline{Y}_0| > c ~|~ H_A\right)\\
&= P\left(\frac{|\overline{Y}_1 - \overline{Y}_0| - \Delta}{2s/\sqrt{n}} > 
\frac{c-\Delta}{2s/\sqrt{n}} ~|~ H_A\right)\\
&= P\left(Z > \frac{c-\Delta}{2s/\sqrt{n}}\right)\\
&= P\left(Z > z_{1-\alpha/2} - \frac{\Delta}{2s/\sqrt{n}}\right) \\
&= 1 - \Phi\left(z_{1-\alpha/2} - \frac{\Delta}{2s/\sqrt{n}}\right)
\end{align*}

### Notes on power \ldots

The power is an increasing function of the standardized difference:
\[ \mu_T(\triangle) =  \frac{\triangle}{2s / \sqrt{n}} \]

This is the number of standard errors between the two means, under the assumption of equal variances.

\begin{enumerate}
\item As $n$ increases, the power increases.
\item For fixed $n$, the power increases with $\triangle$.
\item For fixed $n$ and $\triangle$, the power decreases with $s$.
\item Assigning equal numbers of patients to the two groups 
$(n_1=n_0=n/2)$ is best for maximizing power.
\end{enumerate}



### Step 3: sample size as a function of power

From the calculation for power:

\begin{align*}
1 - \beta &= 1 - \Phi\left(z_{1-\alpha/2} - \frac{\Delta}{2s/\sqrt{n}}\right) \\
&\Longrightarrow \beta = \Phi\left(z_{1-\alpha/2} - \frac{\Delta}{2s/\sqrt{n}}\right) \\
&\Longrightarrow z_{1 - \beta} = z_{1 - \alpha/2} - \frac{\Delta}{2s/\sqrt{n}} \\
&\Longrightarrow z_{\beta} + z_{1 - \alpha/2} = \frac{\Delta}{2s/\sqrt{n}} \\
&\Longrightarrow n  = \frac{(z_{1-\alpha/2} + z_{1-\beta})^2 4 s^2} {\Delta^2} \\
\end{align*}


### Notes on sample size

\begin{enumerate}
\item  Sample size increases as $s$ decreases.
\item  Sample size increases as power increases.
\item  Sample size increases as $\alpha$ decreases.

\end{enumerate}

### An example

Derive the total sample size required for  90\% power for detecting a difference of 0.5 standard deviations between means, based on a two-sided 0.05 level test.  

\begin{center}
\begin{tabular}{rcl}
$\alpha$                   & = & ~0.05 \\[1ex]
$z_{1-\frac{\alpha}{2}}$   & = & ~1.96 \\[1ex]
$\beta$                    & = & ~0.10 \\[1ex]
$z_{1 - \beta} = z_{0.90}$ & = & ~1.28 \\[1ex]
\end{tabular}
\end{center}

\begin{align*}
n &=  \frac{\left(1.96  + 1.28 \right)^2
4 s^2}{\triangle^2} ~ \approx ~ \frac{42 ~s^2}{\triangle^2}
\end{align*}

For a 0.5 standard deviation difference, $\Delta/s=0.5$, 
\begin{eqnarray*}
n & \approx & \frac{42}{(0.5)^2} = 168
\end{eqnarray*}

### Calculations in R

In practice, the test statistic is a $t$-statistic, not a $Z$-statistic.

The difference is small when sample sizes are large, but more important for smaller sample sizes.

Best to use software based on the $t$-distribution.
\footnotesize
```{r eval=TRUE, echo=TRUE}

power.t.test(delta = .5, sd = 1, sig.level = 0.05,
             power = 0.9, type = "two.sample",
             alternative = "two.sided", strict = TRUE)
```


# Censored data

### Sample size based on the log-rank test

*Recap of the log-rank*

Consider a two-group survival problem, with equal numbers of individuals in the two groups ($n_0$ in group 0 and $n_1$ in group 1).  

Let $\tau_1,...,\tau_K$ represent the $K$ ordered, distinct failure times, and at the  $j$-th event time:

\begin{center}
\begin{tabular}{cccc}
\hline
& \multicolumn{2}{c}{Fail} & \\ \cline{2-3}
\multicolumn{1}{c}{Group } & ~~~Yes~~~ & ~~~No~~~ & Total\\  \hline
0 & $d_{0j}$ & $r_{0j} - d_{0j}$ & $r_{0j}$ \\[1ex]
1 & $d_{1j}$ & $r_{1j} - d_{1j}$ & $r_{1j}$ \\[1ex]
\hline
Total &  $d_j  $ & $r_j   - d_j  $ & $r_j  $  \\ 
 \hline
\end{tabular}
\end{center}

where $d_{0j}$ and $d_{1j}$ are the number of events in group 0 and 1, respectively, at the $j$-th event time, and $r_{0j}$ and $r_{1j}$ are the corresponding numbers at risk.


### The log-rank test statistic ($Z$-statistic version)

\begin{align*}
Z_{LR} &=   \frac{\sum_{j=1}^{K} (d_{1j} - e_j)}{ 
 \sqrt{\sum_{j=1}^{K} v_j}} \qquad \text{ with } e_j = d_j \frac{r_{1j}}{r_j} \\[1ex]
v_j &= r_{1j} r_{0j} d_j(r_j-d_j)/[r_j^2(r_j-1)]
\end{align*}


### Distribution of the log-rank statistic

Suppose that the hazard rates in the two groups are $\lambda_0(t)$ and  $\lambda_1(t)$, with hazard ratio 
\[  \theta= e^\beta = \frac{\lambda_1(t)}{\lambda_0(t)} \]

and suppose $H_0: \beta=\log(\theta)=0$, which is equivalent to $H_0: \theta=1$.

It is possible to show that if there are no ties, and the observed distribution is ``near'' $H_0$,

then

- $E(d_{1j} - e_j | d_{1j}, d_{0j}, r_{1j}, r_{0j})  \approx \log(\theta)/4$

- $v_j  \approx 1/4$


### Distribution of the log-rank statistic \ldots

At a value $\log(\theta)$ under the alternative:
\begin{align*} 
Z_{LR} &\approx  \frac{\sum_{j=1}^K \log(\theta)/4}{\sqrt{\sum_{j=1}^K 1/4}}\\[1ex]
&=\frac{d \log(\theta)/4}{\sqrt{d/4}}\\[1ex]
&= \frac{\sqrt{d} \log(\theta)}{2}\\[1ex]
\text{and } Z_{LR}  &\sim  N(\frac{\sqrt{d} \log(\theta)}{2},1) 
\end{align*} 

### Power of the log-rank test

Using a similar argument to before, the power of a two-sided, level $\alpha$ logrank test  is approximately:

\[ \text{Power} (\theta) \approx 
1 - \Phi\left[z_{1- \frac{\alpha}{2}} - \frac{\sqrt{d} \log(\theta)}{2} \right]  \]

Power depends on only $d$ and $\theta$.

\vspace{0.3in}
Possible to solve for required number of events to achieve a certain power at a specified value of $\theta$\ldots

### Power of the log-rank test\ldots

For $\text{Power}(\theta) = 1-\beta$, $d$ must satisfy 
\begin{align*}
1 - \beta &= 
1 - \Phi \left(z_{1- \frac{\alpha}{2}} - \frac{\sqrt{d} \log(\theta)}{2}\right)\\[1ex]
\Rightarrow  z_{\beta} &=  
z_{1- \frac{\alpha}{2}} - \frac{\sqrt{d} \log(\theta)}{2}\\[1ex]
\Rightarrow  d  &=  
\frac{4 \left(z_{1- \frac{\alpha}{2}} - z_{\beta}\right)^2}
{[\log(\theta)]^2}\\[1ex]
\text{or } d &=  
\frac{4 \left(z_{1- \frac{\alpha}{2}} + z_{1-\beta}\right)^2}{[\log(\theta)]^2} 
\end{align*}

### Example 

Suppose investigators are planning a 2-arm study, and want to detect a hazard ratio of 1.5 with 90\% power at a 2-sided significance level of $\alpha=0.05$.

Required number of events:
\begin{align*}
d &= \frac{4 \left(z_{1- \frac{\alpha}{2}} + z_{1-\beta}\right)^2}
{[\log(\theta)]^2}\\[1ex]
&= \frac{4 (1.96 + 1.282)^2}{[\log(1.5)]^2}\\[1ex]
&\approx \frac{42}{0.1644} = 256
\end{align*}

### Events required for various hazard ratios


\begin{center}
\begin{tabular}{ccc}
Hazard & \multicolumn{2}{c}{\bf Power} \\ \cline{2-3}
Ratio & ~~80\%~~ & ~~90\%~~ \\ \hline
1.5 & 191 & 256 \\
2.0 & ~66 & ~88 \\
2.5 & ~38 & ~50 \\
3.0 & ~26 & ~35 \\
\hline
\end{tabular}
\end{center}

Most studies are designed to detect a hazard ratio of 1.5-2.0.

# Practical considerations

### Practical considerations

- Deciding  on $\theta$
- Translating the number of failures to number of enrolled participants

Easiest to think about this for the hazard ratio $\theta$ of two exponential distributions.

If $T_i \sim exp(\lambda_i)$, then 
\[   \text{Median}(T_i) = -\log(0.5)/\lambda_i \]

It follows that 
\[
\frac{\text{Median}(T_1)}{\text{Median}(T_0)} = \frac{\lambda_0}{\lambda_1} = e^{-\beta} = \frac{1}{\theta}
\]
Doubling the median survival of a treatment group compared to a control group corresponds to halving the hazard.  

### Using $R$-year survival rates with an exponential distribution

Suppose the $R$-year survival rate is $S_1(R)$ in group 1 and $S_0(R)$ in group 0.  

Under the exponential model:
\[ S_i(R) = \exp(-\lambda_i R) \]

Hence,
\[   \frac{\log(S_1(R))}{\log(S_0(R))} 
= \frac{-\lambda_1 R}{-\lambda_0 R} =\frac{\lambda_1}{\lambda_0} =
e^{\beta} = \theta\]

Hence, doubling the hazard rate from group 1 to group 0 corresponds to doubling the log of the $R$-year survival rate.  

Note that this result does not depend on $R$. 


### Example  

Suppose the 5-year survival rate on treatment A is 20\% and investigators want 90\% power to detect an improvement to 30\%.  

The corresponding hazard ratio of treatment to control is:
\[ \frac{\log(0.3)}{\log(0.2)} = \frac{-1.204}{-1.609} = 0.748 \]

From the power formula for the log-rank, the number of events needed to detect this improvement with 90\% power, based on a 2-sided 5\% level test is
\[    d = \frac{4 (1.96 + 1.282)^2}{[\log(0.748)]^2}  =  499 \]

### Translating to number of enrolled patients

Suppose a study enters all $N$ patients at time 0, and will continue the study for $F$ units of time.

Under $H_0$, the probability that an individual will fail
during the study is:
\begin{align*}  
P(fail)   &=    \int_{0}^{F} \lambda_0 e^{-\lambda_0 t} dt\\[1ex]
   &=   1- e^{-\lambda_0 F}\\
\end{align*}
Hence, if power calculations imply the study needs $d$ failures, then

\[  d = (N/2)(1 - e^{-\lambda_0 F}) + (N/2)(1 - e^{-\lambda_1 F})\]

### Translating to number of enrolled\ldots

The solution for $N$ requires values of $F$ and $d$.

1. Assume a HR $\theta$, then calculate $d$.

2. Assume a follow-up period $F$, then calculate $N$.

### Example  

Suppose investigators wish to detect a 50\% improvement in the median survival from 12 months to 18 months with 80\% power at $\alpha=0.05$, and plan to follow participants for 3 years (36 months).

Use the two medians to calculate $\lambda_0$, $\lambda_1$, and the hazard ratio, $\theta$:
\begin{align*}
\text{Median}(T_i) &= -\log(0.5)/\lambda_i \\[1ex]
\text{so } 
\lambda_1 &=  \frac{-\log(0.5)}{M1} = \frac{0.6931}{18} = 0.0385\\[1ex]
\lambda_0 &=  \frac{-\log(0.5)}{M0} = \frac{0.6931}{12} = 0.0578\\[1ex]
\theta &= \frac{\lambda_1}{\lambda_0} = \frac{0.0385}{0.0578} 
= \frac{12}{18} = 0.667
\end{align*}

From the earlier table, the number of events required is $d=191$ (same for
$\theta=1.5$ as it is for $\theta = 1/1.5=0.667$).  

### Example  \ldots

Now solve\ldots
\begin{align*}
191 &=  (N/2)(1 - e^{-0.0578(36)}) + (N/2)(1 - e^{-0.0385(36)})\\[1ex]
    &=  (N/2)(0.875) + (N/2)(0.7500) = (N/2)(1.625)\\[1ex]
\Rightarrow N &= 235
\end{align*}

Round up to 236 and randomize 118 patients to each treatment group.

### Another example

Even if accrual does not all happen at time 0, this formula can be surprisingly useful.

A clinical trial in esophageal cancer will randomize patients to radiotherapy alone (Rx A) versus radiotherapy plus chemotherapy (Rx B).  

  - The goal of the study is to compare the two treatments with respect to survival, using the log-rank test.  

  - From historical data, the median survival on Rx A for this disease is around 9 months.   

  - Want 90\% power to detect an improvement in the median to 14 months.  
  
  - Past studies have been able to accrue approximately 50 patients per year.   


### Esophageal cancer

\small

Start by estimating the number of events the trial will need for 90\% power.

\footnotesize
```{r eval=TRUE, echo=TRUE}
# using years as time scale
alpha = 0.05; beta = 0.10
med.0 = 0.75; med.1 = 14/12

num.events = 4 * (qnorm(1 - alpha/2)+ qnorm(1 - beta))^2 /
  log(med.1/med.0)^2
num.events
```

\small

The trial has to enroll a minimum of 216 patients (with complete follow-up). 

If the anticipated accrual rate (50 patients per year) is correct, the trial could enroll 250 patients over 4 years, then follow participants until 216 events are observed.

  - How long should participants be followed?


### A more realistic accrual pattern

In reality, not everyone will enter the study on the same day.

Instead, the accrual will occur in a ``staggered'' manner over a period of time.

*The standard assumption about enrollment* 

Participants enter the study uniformly over an accrual period lasting $A$ units of time, and that after the accrual period, follow-up will continue for another $F$ units of time. 

The translation  $d$ to $N$ requires the probability that a participant is observed to have an event under this accrual and follow-up scenario.

\begin{align}
\nonumber
P(\text{fail}) &=  
\int_{0}^{A} P(\text{fail}|\text{enter at } a) f(a) da \\[1ex]
&= 1-\frac{\int_{0}^{A} S(a+F)~ da}{A}
\label{exactP}
\end{align}

### A more realistic accrual pattern \ldots

Solve for $d$, where $P_c$ is the proportion of failures in the control group and $P_e$ is the proportion of failures in the experimental group:
\begin{align*}
d &= (N/2) P(\text{fail};\lambda_0) +(N/2) P(\text{fail};\lambda_1)\\
  &= (N/2) P_c + (N/2) P_e\\
  &= (N/2) (P_c + P_e)
\end{align*}

Solve for $N$ based on the previous formula for $d$:
\begin{align*}
N &= \frac{2~d}{(P_c + P_e)}\\[1ex]
N &= \frac{8 ~ \left(z_{1-\frac{\alpha}{2}} + z_{1-\beta}\right)^2}
{[\log(\theta)]^2} \times \frac{1}{(P_c + P_e)}
\end{align*}


### Calculating $P_c$ and $P_e$ from equation (\ref{exactP})

If failure times are exponential distributed,  (\ref{exactP}) implies:

\begin{align} \label{pExp}
P_i &= 1 - \frac{exp(-\lambda_i F) (1-exp(-\lambda_i A))}{\lambda_i A} \qquad \text{ for } i = c, e 
\end{align}

Freedman suggested an approximation for $P_c$ and $P_e$, by computing the probability of an event at the median duration of follow-up, $(A/2 + F)$:
\begin{align*}
P_i = P(\text{fail};\lambda_i) &= 1 - exp[-\lambda_i (A/2 + F)]
\end{align*}

He showed that this approximation works pretty well for the exponential distribution (i.e., it gives values close to (\ref{pExp})).

### Other approximations

Rubenstein, Gail, and Santer (1981) and Lachin and Foulkes (1986) have given more accurate approximations for calculating the probablilty of an event. 

- These methods are more complicated and require software

- Software now widely available in \textsf{R} and other packages

\textsf{R} packages: \texttt{Hmisc}, \texttt{TrialSize},  \texttt{gsDesign}

  - Many other \textsf{R} packages and programs [here](https://cran.r-project.org/web/views/ClinicalTrials.html)

  - \texttt{cpower()} in \texttt{Hmisc} is a simple and robust program for computing power as a function of the ususal parameters

  - \texttt{nSurv()} more complicated to use, but allows many more options

Commercial packages: EaST, nQuery, SAS, etc.

### Using cpower()

Parameters:  

- \texttt{tref}: time point at which mortalities estimated, usually given in years   

- \texttt{n}: total sample size (both groups combined). If allocation is unequal so that there are not n/2 observations in each group, sample sizes can be specified in \texttt{nc} and \texttt{ni}.   

- \texttt{mc}: tref-year mortality, control group, as a decimal. This is the value of the control survivor function at \texttt{tref}.

- \texttt{r}: relative \% reduction in mc by intervention.  A reduction from 50\% to 40\% mortality at time tref is a 20\% reduction.   

- \texttt{accrual}: duration of accrual period, in same units as \texttt{tref}  

- \texttt{tmin}:	minimum follow-up time

### Using cpower()\ldots

- \texttt{noncomp.c}:	\% non-compliant in control group (drop-ins)     

- \texttt{noncomp.i}:	\% non-compliant in intervention group (drop-outs, non-adherers)    

- \texttt{alpha}: type I error probability. A 2-tailed test is assumed.   

- \texttt{nc}: 	number of subjects in control group   

- \texttt{ni}:	number of subjects in intervention group. \texttt{nc} and \texttt{ni} are specified exclusive of n.   

- \texttt{pr}:	set to FALSE to suppress printing of details


### Using cpower() for esophageal cancer example

The parameters:

- \texttt{tref} is 9 months, or 0.75 years, and since that is the median in the control group, \texttt{mc} = 0.5 = $S_c(0.75)$ 
- \texttt{n} = 150 patients enrolled over 3 years 
- \texttt{accrual} = 3, and let us set \texttt{tmin} = 1 year of follow-up
- \texttt{alpha} = 0.05   
- Assume no non-compliance

### Using cpower() for esophageal cancer example \ldots


Calculating \texttt{r}, using approximations \ldots

The median for the intervention is 14 months, so    

- $\lambda_i = \log(2)/(14/12) = 0.59$

- $S_i(0.75) = \exp(-(0.59)(0.75)) = 0.64$

Mortality at 0.75 years is reduced from 50\% to 36\%, a proportionate reduction of  (14/50) = 0.28, or 28\%.



### Using cpower() for esophageal cancer example \ldots

What if we allow 1 year of follow-up?

\scriptsize

```{r eval=FALSE, echo = TRUE}
library(Hmisc)
cpower(tref = 0.75, n = 150, mc = 0.5, 
       r = 28, accrual = 3, tmin = 1, 
       noncomp.c = 0, noncomp.i = 0, 
       alpha = 0.05, pr = TRUE)   
```

---

\scriptsize

```{r eval=TRUE, echo = FALSE, message=FALSE, warning=FALSE}
library(Hmisc)
cpower(tref = 0.75, n = 150, mc = 0.5, 
       r = 28, accrual = 3, tmin = 1, 
       noncomp.c = 0, noncomp.i = 0, 
       alpha = 0.05, pr = TRUE)  
```

### Example: Esophageal cancer

Power of initial guess is too low.

- 67\% power because only 65 + 56 = 121 events

We can increase enrollment time or follow-up time or both.

\texttt{cpower()} can be used to search for a design.

### Searching for a design

\scriptsize
```{r, eval=TRUE, echo=TRUE}
accrual.period = c(3)
followup.period = c(1,2,3,4)
num.accrual.periods = length(accrual.period)
num.followup.periods = length(followup.period)
perc.reduct = 28
p = matrix(0,nrow = num.accrual.periods, ncol = num.followup.periods)
for(jj in 1:num.followup.periods){
  p[1,jj]= cpower(tref = 0.75, n = 150, mc = .50, r = perc.reduct, 
       accrual = accrual.period, tmin = followup.period[jj], 
       noncomp.c = 0, noncomp.i = 0, 
       alpha = 0.05, pr = FALSE)
  }
p
```

\normalsize

A more thorough search\ldots

---

\scriptsize

```{r eval=FALSE, echo=TRUE}
accrual.period = c(3,5,7,9)
enrollment.total = 50*accrual.period
followup.period = c(1,3,5,7)
num.accrual.periods = length(accrual.period)
num.followup.periods = length(followup.period)
perc.reduct = 28
p = matrix(0,nrow = num.accrual.periods, ncol = num.followup.periods)
for(ii in 1:num.accrual.periods){
   for(jj in 1:num.followup.periods){
     p[ii,jj]= cpower(tref = 0.75, n = enrollment.total[ii], 
                      mc = .50, r = perc.reduct, 
                      accrual = accrual.period[ii], 
                      tmin = followup.period[jj], 
                      noncomp.c = 0, noncomp.i = 0, 
                      alpha = 0.05, pr = FALSE)
   }
}
power.table = matrix(0, nrow = num.accrual.periods + 1,
                     ncol = num.followup.periods + 1)
power.table[1,] = c(0, followup.period)
power.table[,1] = c(0, accrual.period)
for(ii in 1:num.accrual.periods){
  for(jj in 1:num.followup.periods){
  power.table[ii + 1, jj + 1] = p[ii,jj]
  }
}

power.table 
```

---

\scriptsize

```{r eval=TRUE, echo=FALSE}
accrual.period = c(3,5,7,9)
enrollment.total = 50*accrual.period
followup.period = c(1,3,5,7)
num.accrual.times = length(accrual.period)
num.followup.times = length(followup.period)
p = matrix(0,nrow = num.accrual.times, ncol=num.followup.times)

for (ii in 1:num.accrual.times){
   for(jj in 1:num.followup.times){
     p[ii,jj]= cpower(tref = 0.75, n = enrollment.total[ii], 
                      mc = .50, r = perc.reduct, 
                      accrual = accrual.period[ii], 
                      tmin = followup.period[jj], 
                      noncomp.c=0, noncomp.i=0, 
                      alpha=0.05, pr=FALSE)
   }
}
power.table = matrix(0,nrow=num.accrual.times + 1,
                     ncol=num.followup.times + 1)
power.table[1,] = c(0,followup.period)
power.table[,1] = c(0, accrual.period)
for (ii in 1:num.accrual.times){
  for(jj in 1:num.followup.times)
  power.table[ii + 1, jj + 1] = p[ii,jj]
}
```

```{r eval=TRUE, echo=TRUE}
rownames(power.table) <- c("yrs follow-up", rep("-", 4))
colnames(power.table) <- c("yrs enrollment", rep("-", 4))
round(power.table, digits = 3)
```

\normalsize

Studies often need to be larger than anticipated.

Take a closer look at the design with 5 years of enrollment and 3 years of follow-up.


---

\scriptsize

```{r eval=TRUE, echo = FALSE, message=FALSE}
library(Hmisc)
cpower(tref = 0.75, n = 50*5, mc = 0.5, 
       r = 28, accrual = 5, tmin = 3, noncomp.c = 0, noncomp.i = 0, 
       alpha = 0.05, pr = TRUE)   
```

### What is the effect of non-compliance?

ITT: analyze according to assigned treatment, not treatment received. \medskip

Main justification:

- $p$-values are calculated assuming no treatment difference (the null hypothesis)

- Under that assumption, assigned treatment does not affect outcome

- $p$-values will be correct (valid) when comparing the two groups according to treatment assignment

Example may help make this clear.


### Simple trial, no difference, non-random crossover

Suppose two treatments ($A$ and $B$) are equally effective.

100 participants randomized to each treatment.

ITT table:

-------------------------------------------------
 Response     Treatment $A$        Treatment $B$
----------- ---------------- --------------------
 Success         40              40 

 Failure         60              60 

-------------------------------------------------

Now assume, after randomization:

- 10 participants with good prognosis (future responders) switch from $A$ to $B$

- 10 participants with bad prognosis (future non-responders) switch from $B$ to $A$


### Simple trial, no difference, non-random crossover\ldots

Two treatments still equally effective.

Table for the as-treated groups:

-------------------------------------------------
 Response     Treatment $A$        Treatment $B$
----------- ---------------- --------------------
 Success         30              50 

 Failure         70              50 

-------------------------------------------------


An as-treated analysis would imply that $B$ is more effective than $A$.

### Simple trial, difference, random crossover

ITT can be biased when there is a real treatment effect (random crossovers).

Suppose $B$ is more effective than $A$, so for 100 in each group:

-------------------------------------------------
 Response     Treatment $A$        Treatment $B$
----------- ---------------- --------------------
 Success         30              50 

 Failure         70              50 

-------------------------------------------------

Assume 10 randomly chosen participants from each group switch treatments after randomization but before starting treatment.


### Table with only patients who do not switch

-------------------------------------------------
 Response     Treatment $A$        Treatment $B$
----------- ---------------- --------------------
 Success         27              45 

 Failure         63              45 

-------------------------------------------------

Attrition did not change measured success rates, but...

- does reduce the effective sample size

What happens when `switchers' are put back in?

- 10 $A$ $\rightarrow$ $B$, 5 respond, 5 do not

- 10 $B$ $\rightarrow$ $A$, 3 respond, 7 do not

### ITT table with assigned treatment, real response 

$A$ gets 5 responders (who received B)

$B$ gets 3 responders (who received A)

-------------------------------------------------
 Response     Treatment $A$        Treatment $B$
----------- ---------------- --------------------
 Success         32              48 

 Failure         68              52 

-------------------------------------------------  

Apparent success rate: 

- $A$: 32% after crossover vs. 30% before crossover

- $B$: 48% after crossover vs 50% before crossover

Response proportions have moved closer together.

Non-random attrition can also cause bias in the analysis because of missing data.


### Accounting for non-compliance

If some patients do not take their assigned treatments, power of the study will decrease. This issue has two sides:

*Drop-outs* ($d_e$)

  - Patients who cannot tolerate the medication stop taking it.

  - Their hazard rate would become the same as the placebo group (if included in study) at that point.

*Drop-ins* ($d_c$)

  - Patients assigned to less effective therapy may not get symptom relief and seek other therapy, or request to cross over.

A conservative remedy: adjust $P_e$ and $P_c$ as follows:

\begin{align*}
P_e^{*} &= P_e (1-d_e) + P_c d_e\\[1ex]
P_c^{*} &=  P_c (1-d_c) + P_e d_c
\end{align*}

### Esophageal cancer, again

- Treatments for cancer are often toxic, and patients have difficulty adhering to regimens.

- \texttt{cpower()} can incoporate non-adherence through the parameters \texttt{noncomp.c, noncomp.i}.

- What happens to power with 20\% non-adherence on the intervention arm?

---

\scriptsize

```{r eval=TRUE, echo = TRUE, message=FALSE}
library(Hmisc)
cpower(tref = 0.75, n = 50*5, mc = 0.5, 
       r = 28, accrual= 3, tmin = 3, noncomp.c=0, noncomp.i=20, 
       alpha=0.05, pr=FALSE)
```

### What about attrition


*Attrition* happens when participants leave a study; treatment and outcome assessments cannot be made.

Attrition is also called *loss to follow-up* and is common in long term follow-up for studies of chronic diseases.

\texttt{cpower()} cannot adjust for attrition, but \texttt{nSurv()} in the package \texttt{gsDesign} can.

A lab exercise uses \texttt{nSurv()} to reproduce the design of the SPRINT trial summarized at the beginning of this unit.




# Derivations

### Heuristic proof of the distribution of the log-rank


\begin{align*} 
 E(d_{1j} | d_{1j}, d_{0j}, r_{1j}, r_{0j}) 
    &= P( d_{1j} = 1 | d_{j}=1, r_{1j}, r_{0j}) \\[1ex]
    &=  \frac  {r_{1j} \lambda_0 \theta}
    {r_{1j} \lambda_0 \theta + r_{0j} \lambda_0}\\[1ex]
     &=  \frac  {r_{1j}  \theta} {r_{1j}  
\theta + r_{0j} }\\[1ex]
     &=  \frac  {r_{1j}} {r_{1j} + r_{0j} } + \log(\theta) 
      \left[\frac  {r_{1j}r_{0j}} {(r_{1j} + r_{0j})^2}\right]  \\
\end{align*}

But $e_j = r_{1j}/(r_{1j} + r_{0j})$, so:
\[    E(d_{1j} | d_{1j}, d_{0j}, r_{1j}, r_{0j}) - e_j =
 \log(\theta) \left[\frac  {r_{1j}r_{0j}} {(r_{1j} + r_{0j})^2 }\right] \]

### Heuristic proof of the distribution\ldots

If $n_0=n_1$, then near H$_0$, $r_{1j} \approx  r_{0j}$, hence,
\[    E(d_{1j} | d_{1j}, d_{0j}, r_{1j}, r_{0j}) - e_j = \log(\theta) /4 \]


Similarly, with no ties, 
\[ v_j = r_{1j} r_{0j}/r_j^2 \approx 1/4 \]

### Alternative derivation using the partial likelihood

\small

The partial likelihood is:
\begin{align*}
  l(\bbeta)   &=  \log \left[ \prod_{j=1}^{n}\left(    \frac
      {   e^{\bbeta \bZ_j } }   {\sum_{\ell \in {\cal R}(\tau_j)}
e^{\bbeta \bZ_{\ell}} }\right)^{\delta_j} \right]  \\[1ex]
&=\sum_{j=1}^{n} \delta_j  \left[ \bbeta \bZ_j  -
\log \left(\sum_{\ell \in {\cal R}(\tau_j)} e^{\bbeta \bZ_{\ell}}\right) 
\right]
\end{align*}

The partial derivative of log-likelihood (the score statistic) is:
\begin{align*}
U(\bbeta)   &=  \frac{\partial}{\partial \bbeta} \ell(\bbeta) \\
&=  \sum_{j=1}^{n} \delta_j  \left[ \bZ_j  -
\frac{ \sum_{\ell \in {\cal R}(\tau_j)} \bZ_{\ell} ~e^{\bbeta \bZ_{\ell}} }
{ \sum_{\ell \in {\cal R}(\tau_j)}   e^{\bbeta  \bZ_{\ell}} } \right]
\end{align*}

### Partial likelihood derivation \ldots

The negative second partial derivative of the log-likelihood) is:
\footnotesize
\[
-\frac{\partial^2}{\partial \bbeta^2} \ell(\bbeta) =
 \sum_{j=1}^{n}   \delta_j \left[     
\frac{ \sum_{\ell \in {\cal R}(\tau_j)} e^{\bbeta \bZ_{\ell}}
\sum_{\ell \in {\cal R}(\tau_j)} \bZ_{\ell} e^{\bbeta \bZ_{\ell}}-
(\sum_{\ell \in {\cal R}(\tau_j)} \bZ_{\ell} e^{\bbeta \bZ_{\ell}})^2}
{ \sum_{\ell \in {\cal R}(\tau_j)} e^{\bbeta  \bZ_{\ell}} } \right]
\]

\normalsize
The logrank statistic (with no ties) is equivalent to the score statistic for testing $\bbeta=0$:
\[
Z_{LR} = \frac{U(0)}{\sqrt{I(0)}}
\]
By a Taylor series expansion:
\[U(0) \cong U(\beta)- \beta \frac{\partial U}{\partial \beta}(0)\]
\[E[U(0)]\cong \beta d /4 \hspace{0.3in} \text{and ~} I(0)\cong d/4\]
